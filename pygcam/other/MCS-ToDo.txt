BUGS
* using groupName even when useGroupDir=0 in scenarios file
  * for some reason adding symlink to correct for this didn't work either
  * run sim for paper1 on mac to debug


Improvements
* -n flag should be unnecessary
  * use -t or other indications of how many trials to run
  * reinstate -C flag to start engines?
  * Or just assume engines are needed unless -L or -a are used
* Wait to exit if there are pending engines waiting to run.
* If a given % of runs have failed, stop the MCS
* Have a mode to find missing runs based defined number of trials.
  * Run any baselines that are not in the run table
  * Run any non-baseline scenarios that haven't run, for which there is
    a successful baseline scenario.
  * Add a run.status to indicate a scenario with a failed baseline.
    * write a file into baseline dir to indicate success, so scenarios
      can check for this before running (without engines hitting the DB.)
      * remove the "success" file at the start of a run, write it at end
  * Loop over all untested trials until no more can be run
    * this allows for baselines completing, allowing other runs to begin

It's all engines have exited another pending in their runs left to do, launch more engines.

Abort a non-baseline if the baseline hasn't succeeded.
- could determine this in master and not even queue the job

Repurpose the sigalarm: set it to the walltime of the engine
minus the GCAM.MinimumTimeToRun. When it signals the engine,
set a flag "quitWhenDone" so the engine exits after returning
the current result. (How to do this without accepting another
task?)

* Figure out source of "too many files open" complaint. Might be looping in master.py?

Overnight run:
  * runs succeeded but write to DB failed.  Might have been another runsim -L in the background.

* Test runsim -C/--collectResults

Handle this, which gets repeated once it occurs:

  WARNING checkRunning: KeyError(u'6c87e47f-0777-4f66-8071-80093f4b0cf2')

* loop over tasks rather than processing all together in one get_results() call,
  so individual exceptions can be processed / ignored, without losing good results.

JobNum is now meaningless. Excise it from the code and database.

* See why XMLDBDriver.properties is getting written with empty values

* See if updating sqlalchemy solves thread issue

* Running queries in GCAM should be implied if a filter file is defined.

* Figure out why there's a pool error at start with SqlAlchemy

* Running gensim > once doesn't create new sims, it overwrites simId 1.

* Deprecated newsim
  * remove from docs, __init__ and so on

* If status == 'killed', resubmit the task.

* Trials are not setting running status if either added via -a or via newly added engines.

* Need a simple test suite to try out a few things and understand error modes
  * Start cluster with N engines
  * Add engines to running cluster
  * Add tasks to running cluster (some tasks are added, others go "missing". Why?)
  * Recover from engine being killed
  * Recover from failures getting results (unclear when/why)

* Simplify database handling of duration
  * Have worker track start / end time, store these in result structure
  * Master can compute duration and write this to run table

* Might be an issue with one client calling get_result() on task queued by other client.
  * Try using db_query to get this instead?

* When adding engines and tasks, the new tasks' run.status isn't updated from new
  as it is with jobs created by master itself.

Command clean-up
-----------------

The following are probably obsolete or can be merged into other commands:
- addexp : this is now automatic. Is there ever a need to add one manually?

API
---
Create function to read inputs and results from db and
create joined or separate DataFrames from these.

Redesign analytic and plotting functions to expect use these.

Should be compatible with SALib (or layer built on that).

Build MonteCarlo class in sensitivity.py to conform with other versions.

CorrelationDef.py appears unused. Is this all now handled in
XMLParameterFile?

Merge pygcamSupport.py into appropriate modules.

tsplot
------
The monkey patch at
http://stackoverflow.com/questions/34293687/standard-deviation-and-errors-bars-in-seaborn-tsplot-function-in-python
might be preferable to current approach.

Documentation
-------------
- Setup read the docs project

MCS / SALib
-----------
- Test both adding engines dynamically and adding runs.
  - Test runsim --addTrials

- shutdownWhenIdle happens in all cases

- It would be useful to have conditional evaluation in project.xml and scenarios.xml
  e.g., to have different behavior in MCS mode.

- Need to be able to
  - Add engines to existing cluster
    - gt engine does this but might want to specify a different queue
    - currently it reuses the batch file created by startCluster. No need to do this.

- Seem to have solved the sqlite thread problem, but the start/end times are not
  being updated. Is this because the call-back is registered in one thread only?

- Modify legacy approach to sampling and SA to look like SALib versions, i.e.,
  subclass sensitivity.SensitivityAnalysis and write _sample / _analyze methods.

- Document: If SALib methods are used, must define as triangle or uniform
  i.e., requires fixed max and min.

- Create Workspace and Sandbox classes that encapsulate the diffs
  between stochastic and non-stochastic runs, simplifying the creation
  of these directories and their various symlinks (and avoiding the
  currently redundant links), and access to various logical paths.

- Generate tornado plot from Sobol analysis.
  - Should "just work" once values are in the database
  - See how Platypus presents Sobol results.

Once paper1 analysis is done:
- Create new branch
- Drop InValue row and col columns from schema, Database, uses
- Add variable number?
  - Useful only for independent (non-shared) RVs, which currently don't work.

- Create an "export" subcommand that can output inputs/outputs in various
  formats, e.g., for SALib, for EMAWorkbench? and so on.

- Also, "plotsim" to provide various types of plots
- Also, "sa" to run the global sensitivity analysis associated with
  the sampling method used in "gensim".

- Might be able to eliminate distinction between static and dynamic

- Merge mcs-cluster.py into analysis.py

- Test each new sub-command
  - Step through all code
  - Fix config vars one at a time.

- Have "newsim" command append to .pygcam.cfg as "new" does (optional)

- Make MCS.Years obsolete
  - need single point of modification, either project.xml or config file, not both!
  - in the meantime, might check that the designated years are correct in the database

- Modify XMLConfigFile to use xmlEditor since same features exist there?
  - different calling assumptions might make this difficult

Master/worker architecture
---------------------------
- Seems workers are added for 30min only.
  - Check logic on that. Might be adding workers up to 300 before adding time?
  - Added engines, but didn't seem to be picked up by master, not sure though. CHECK LOGS.

- Rather than calling ipcluster -n 0 and ipengine --daemonize, just call
  ipcontroller and sbatch the generated engine batch file.
  - Generate these into profile dir, but set the working dir for log output
    to {simdir}/logs

- Runsim prints both console and "file" log messages
  - need to be able to assign log level and log file per module.

- Consolidate logging / console msgs
  - GCAM output going to exe/logs/main_log.txt
  - Engine output going to trialDir/log/{scenario}.log
  - Non-GCAM (logger) output going to ~/tmp/slurm-*.log files
  - unclear where controller is logging to with --log-to-file=True

- Setup stuff
  - Automate configuration of ipyparallel files (ipcluster and ipcontroller files)

  - conda update conda
  - conda install packaging appdirs
  - python setup.py develop in pygcam and pygcam-mcs

  - Create new profile:
    ipython profile create --parallel --profile=pygcam

  - on PIC set these in ~/.ipython/profile_pygcam/ipcontroler_config.py:
    # seems to be a name changed... in 5.2.0 there are only
    # c.HubFactory.client_ip and c.HubFactory.engine_ip
    c.HubFactory.ip = '*'

    # Set engines to use Slurm, but leave controller on login node to avoid
    # hogging an additional node for this mostly-idle task
    c.IPClusterEngines.engine_launcher_class = 'Slurm'

    # Itâ€™s also useful on systems with shared filesystems to run the engines
    # in some scratch directory. This can be set with:
    c.IPEngineApp.work_dir = u'/path/to/scratch/'

- Revise file layout to minimize need for copying (see notes in pygcam files)
