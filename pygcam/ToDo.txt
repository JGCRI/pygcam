Bugs
----
- Diff without -i is still interpolating.

Cleanup
-------
- Eliminate "scenarios.xml" from gcammcs? Obviated by project.xml?
  - Check whether it's used by gcammcs

Test
----
- setup.py installer with full install
- write more unit tests
- changes to XML format and validation
    - pygcam and also gcammcs (results, parameters, scenarios)
- land protection command
    - uses new resource_stream function; not tested yet

Features
--------
- Test pyfunc capability and use it to generate protected areas based on
  distro.

- Create in otaq2016 a module (or use scenarios.py, logically) a func
  that takes an XMLInputFile as an input, and calls createProtected:

  createProtected(xmlFile.tree, fraction, landClasses=UnmanagedLandClasses, regions=None)

  But prior to that, have a python func that is passed an np.array
  produced by some distribution, which is stored in the module for use
  when the writeFunc is called. This way the parameter is processed
  normally.

- In chart subcommand, allow args to -m (multiplier) to take symbolic
  values like EJ_to_Quad, where these are driven by a builtin table
  with common ones, augmented if needed by a user file, e.g.,

    GCAM.UnitMultipliers = %(ProjectRoot)/etc/multipliers.txt

    Could have, e.g.,

    EJ_per_km2_to_Quad_per_Mha =

    could even do this as a python file that is interpreted, or
    as a cfg file where final expression is evaluated with the
    list of variables in a namespace that is passed.

    See unitConversion.py for values gleaned from PNNL files.

- Allow plotting a marker at the total for a bar

- Allow overlay of, say, line chart using right Y axis on barchart
  using left Y axis, as in "US Land Cover and LUC Emissions"

- Generalize the mapping capability beyond region maps.
  - Write a tmp XML file identical to the <queries> element
     - project.py doesn't need to interpret the XML at all. It's validated
       by project-schema.xsd. Just write it to a temp file and store name
       in varName.

- Modify case with batchfile by name so it is copied to the tmp file and the
  rest proceeds as with query definition files.

- Have a flag for batch mode that runs the baseline, then batches
  the policy scenarios with '-d singleton' to cause them to wait
  for the baseline to complete.
  - Maybe --split => split the scenario to run in own batch jobs
    rather than running them all in one big job. If the scenarios
    include baseline and at least one policy scenario, add args
    "-d afterok:<jobid>" to existing value of GCAM.OtherBatchArgs,
    where <jobid> is the id of the baseline job.
  - use subprocess.check_output() and look for "Submitted batch job (\d+)"

- If scenario has unique name among groups, run it even if group isn't specified?
    - Will require restructuring since it's assumed there's one group name

- Specify a simple project without writing custom python code.
    - Create xmlsrc
    - Use built-in scenarios.py that just needs scenario names,
      called from runProj
    - <scenario> has a <files> section similar to configuration.xml
    - support a delete="true" attribute
    - Use stopYear to limit run

- A "simple" project either:
    - Has manually creates sandboxes
    - Has generated sandboxes, but the project only adds to and
      removes from configuration.xml with references to local files.

- Code doesn't use XmlEditor
    - Already supported using scenarios.py

- Advantages of this setup
    - Standardized and documented format
    - Easily transition to using additional pygcam features
    - Simplifies sharing of experiments, e.g., via git

Other
-----

- Generalize as many of the Bioenergy and Refining methods as possible
    - Goal should be to not need any sector-based methods

- Integrate gcam-driver code / ideas
    - Consider re-implementing using jug

- Make seq="x" optional in project <step> definitions; use order as defined.
  If user is not overriding any steps (most common use case), explicit seq
  nums are not needed.
  - Another option is to have an explicit <step after="stepname">, to create
    dependence DAG, which leads toward gcam-driver type of functionality.

- pygcam/etc/site.cfg
    - see what happens with this on installation via setup.py
    - would be much better outside the installed module
    - maybe use an environment var, e.g., PYGCAM_SITE_CONFIG_FILE

- Host the xsd files somewhere dependable so they can be referenced in XML
  files, allowing smart editing.

Document
--------
- queryMapping
  - default "level" set in query itself, can override in query list
  - append-values="false" unless any of the queries sets it to "true"

- <defaults> is now optional

- Document the Subcommand (plugin) protocol
    - class 'Plugin' or variable PluginClass which identifies classname
    - addArgs()
    - run(args, tool)
    - when it gets loaded and run
    - other suggestions, e.g., plugins should use logging

- Assumptions behind setup code

- Eliminate the need for *.pth files for scenarios.py files: we can
  load them directly by pathname.

  # Apparently have to load intermediate module first, as below
  import imp
  modDir  = '/Users/rjp/bitbucket/otaq2016/xmlsrc'  # replace with xmlSrcDir
  modName = 'xmlsrc'

  # load group module level if required
  if args.groupDir:
     modDir  += '/' + args.groupDir
     modName += '.' + args.groupDir
     imp.load_source(modName, modDir)

  mod = imp.load_source(modName + '.scenarios', modDir + '/scenarios.py')


Tasks
-----
- Modify CI command to use Marshall's query results
- Test diff cmd
- Test constraint cmds
- Test land protection cmd
    - Simplify to eliminate complicated cmdline opts?
- Should constraint commands be converted back to plugins?
    - They're for use by biofuel studies only (maybe a sep plugin dir?)
    - Perhaps split out generic function from domain-specific
- Update documentation


MCS Integration
===============

- Trial generation should be unaffected
    - document ordering: setup first then gensim

- Needs wrapper (runner.py) or jug-type master-slave approach
    - master-slave avoids stacking jobs in advance
    - jug handles tracking incomplete jobs

- Using jug
    - Slave asks for next task
        - identified by path to .json file, which has all needed args
    - Does stuff that runner.py does now
        - signal handling
        - sets per-task alarm
        - database updates (unless jug results mgmt obviates this)
        - returns status or tuple/dict with more info?

GUI implementation
==================
- Focus on "project"
- Create an edit project.xml
- Run a project
    - select groups, scenarios, and steps to run (checkboxes)
    - select direct or batch mode
        - if direct, show output in window
    - have a 'kill' command for local or batch (sdel?)
- View & update config file
